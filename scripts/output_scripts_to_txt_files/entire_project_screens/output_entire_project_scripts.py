#!/usr/bin/env python3
import os
import subprocess
import sqlite3
from pathlib import Path
import hashlib
import logging
import time
import sys

# --- Config ---
PROJECT_ROOT = Path("/Users/stevencohen/Projects/universal_recycling/orders_project")
OUTPUT_FILE = PROJECT_ROOT / "all_project_scripts.md"
LOG_FILE = PROJECT_ROOT / "logs/output_scripts.log"
DB_FILE = PROJECT_ROOT / "data/orders.db"

INCLUDE_DIRS = [
    PROJECT_ROOT / "backend",
    PROJECT_ROOT / "frontend",
]
INCLUDE_EXTENSIONS = {'.py', '.js', '.html'}
EXCLUDE_DIRS = {'scripts', 'logs', 'data', 'uploads', 'venv'}

# --- Logging Setup ---
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

missed_files = []         # Files that failed to open
written_files = set()     # Files successfully written to MD
expected_files = set()    # All eligible .py/.js/.html files found


def get_file_hash(file_path):
    try:
        sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256.update(chunk)
        return sha256.hexdigest()
    except Exception as e:
        logging.error(f"Failed to hash {file_path}: {e}")
        return None


def get_file_mtime(file_path):
    try:
        mtime = os.path.getmtime(file_path)
        return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(mtime))
    except Exception as e:
        logging.error(f"Failed to get mtime for {file_path}: {e}")
        return "Unknown"


def get_directory_tree():
    try:
        result = subprocess.run(
            ["tree", "-L", "5", str(PROJECT_ROOT)],
            capture_output=True,
            text=True,
            check=True
        )
        logging.info("Directory tree generated successfully")
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error generating directory tree: {e}")
        return f"Error generating directory tree: {e}"


def get_database_schema():
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute("SELECT name, sql FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
        schema = [
            f"### Table: {name}\n```sql\n{sql}\n```"
            for name, sql in cursor.fetchall()
        ]
        conn.close()
        return "\n\n".join(schema) if schema else "No tables found in database."
    except sqlite3.Error as e:
        logging.error(f"Error accessing database: {e}")
        return f"Error accessing database: {e}"


def collect_files(directory):
    contents = []
    for root, _, files in os.walk(directory):
        rel_root = Path(root).relative_to(PROJECT_ROOT)
        if any(part in EXCLUDE_DIRS for part in rel_root.parts):
            continue

        for file in sorted(files):
            file_path = Path(root) / file
            ext = file_path.suffix
            if ext not in INCLUDE_EXTENSIONS:
                continue

            relative_path = file_path.relative_to(PROJECT_ROOT)
            expected_files.add(str(relative_path))  # Mark as expected

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                file_hash = get_file_hash(file_path)
                file_mtime = get_file_mtime(file_path)
                line_count = len(content.splitlines())

                contents.append(
                    f"### File: {relative_path}\n"
                    f"**SHA-256 Hash**: {file_hash}\n"
                    f"**Line Count**: {line_count}\n"
                    f"**Last Modified**: {file_mtime}\n"
                    f"```{ext[1:]}\n{content}\n```"
                )
                written_files.add(str(relative_path))  # Mark as written
            except Exception as e:
                missed_files.append(str(relative_path))
                logging.error(f"Error reading file {relative_path}: {e}")
                contents.append(
                    f"### File: {relative_path}\n"
                    f"(Error reading file: {e})"
                )

    return contents


def main():
    print("üõ† Generating full project script dump...")
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write("# Orders Project Scripts\n\n")
            f.write("Generated by integrity-verified script to capture .py, .js, .html scripts, directory tree, and DB schema.\n\n")

            # Tree
            f.write("## Directory Tree\n```\n")
            f.write(get_directory_tree())
            f.write("```\n\n")

            # Schema
            f.write("## Database Schema\n")
            f.write(get_database_schema())
            f.write("\n\n")

            # File contents
            f.write("## File Contents\n")
            for directory in INCLUDE_DIRS:
                rel_dir = directory.relative_to(PROJECT_ROOT)
                f.write(f"### Directory: {rel_dir}\n")
                contents = collect_files(directory)
                for entry in contents:
                    f.write(entry + "\n\n")

        # Verification
        skipped = sorted(expected_files - written_files)

        if missed_files or skipped:
            print("\n‚ùå The following files were NOT included in the markdown output:")
            for file in sorted(set(missed_files + skipped)):
                print(f"- {file}")
            sys.exit(1)
        else:
            print("\n‚úÖ All files read and written successfully.")
            sys.exit(0)

    except Exception as e:
        logging.error(f"Fatal error during dump: {e}")
        print(f"\n‚ùå Fatal error. See {LOG_FILE} for details.")
        sys.exit(1)


if __name__ == "__main__":
    main()
